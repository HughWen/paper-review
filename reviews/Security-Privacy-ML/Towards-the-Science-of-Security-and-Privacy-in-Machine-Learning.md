# Towards the Science of Security and Privacy in Machine Learning

## Abstract

In recent years, the machine learning is used in a dizzying array of applications. The authors write this survey to articulate a comprehensive threat model for ML and categorize attacks and defenses within an adversarial framework.

## Introduction

In introduction part, the authors firstly state the popularity of ML and lead to the issues of privacy and security. Then, the authors claim that their motivation and challenge is the fragmentation of these several area: machine learning, security, and so on. So the authors decide to systematize knowledge about the myriad of security and privacy issues that involve ML. This paper develop a unified perspective on security and privacy in ML.

The contributions of this paper are:
- Inroducing a unifying threat model to allow structured resonning about the security and privacy of systems that incorporate machine learning (section 3).
- Taxonomizing attacks and defenses identified by the various technical communities s informed elements of PAC learning theory (section 4, 5, 6).
- Introducing a "no free lunch theorem" for adversarial machine learning (section 7).
  
<!-- ### new words

- gone unheeded
- unified lexicon
- the myriad of
- instructive
- through the prism of
- clinical
- paramount
- conversely
- in essence
- distribution drift
- adequately
- accountability
- facet
- depart from
- texonomize
- for brevity -->

## About Machine Learning

In this section, the authors provides an overview of how systems apply ML algorithms. Be worth mentioning, most of work on ML security and privacy to date fall with supervised settings, especially in the context of classification tasks.
This section contains four part: An overview of machine learning tasks, Data collection, Machine learning empirical process, a theoretical model of learning.

<!-- ### new words

- propotion
- underpining
- noteworthy point -->

## Threat Model

In this section, the authors taxonomize the definition and scope of threat models in ML systems and map the space of security models, which contains the machine learning attack surface, the adversarial capabilities and the adversarial goals.

<!-- ### new words

- subvert
- corrupt
- tamper
- disposal
- grossly speaking
- arguably -->